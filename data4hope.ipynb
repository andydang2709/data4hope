{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2013 fetched and processed successfully.\n",
      "Data for 2014 fetched and processed successfully.\n",
      "Data for 2015 fetched and processed successfully.\n",
      "Data for 2016 fetched and processed successfully.\n",
      "Data for 2017 fetched and processed successfully.\n",
      "Data for 2018 fetched and processed successfully.\n",
      "Data for 2019 fetched and processed successfully.\n",
      "Data for 2020 fetched and processed successfully.\n",
      "Data for 2021 fetched and processed successfully.\n",
      "Data for 2022 fetched and processed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_black_prop\"] = black / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_indian_prop\"] = indian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_asian_prop\"] = asian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_PI_prop\"] = pi / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_veteran_prop\"] = veteran / pop_count\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_less_hs_prop\"] = less / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:206: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hs_prop\"] = hs / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_college_prop\"] = college / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_male_prop\"] = male / total_sex\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_female_prop\"] = female / total_sex\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_disability_yes_prop\"] = dis_yes / total_dis\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_disability_no_prop\"] = dis_no / total_dis\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hispanic_prop\"] = hispanic / total_hisp\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_nonhispanic_prop\"] = nonhispanic / total_hisp\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:189: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_white_prop\"] = white / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_black_prop\"] = black / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_indian_prop\"] = indian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_asian_prop\"] = asian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_PI_prop\"] = pi / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_veteran_prop\"] = veteran / pop_count\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_less_hs_prop\"] = less / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:206: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hs_prop\"] = hs / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_college_prop\"] = college / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_male_prop\"] = male / total_sex\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_female_prop\"] = female / total_sex\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_disability_yes_prop\"] = dis_yes / total_dis\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_disability_no_prop\"] = dis_no / total_dis\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hispanic_prop\"] = hispanic / total_hisp\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_nonhispanic_prop\"] = nonhispanic / total_hisp\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:189: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_white_prop\"] = white / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_black_prop\"] = black / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_indian_prop\"] = indian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_asian_prop\"] = asian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_PI_prop\"] = pi / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_veteran_prop\"] = veteran / pop_count\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_less_hs_prop\"] = less / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:206: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hs_prop\"] = hs / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_college_prop\"] = college / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:165: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_male_prop\"] = male / total_sex\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_female_prop\"] = female / total_sex\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_disability_yes_prop\"] = dis_yes / total_dis\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_disability_no_prop\"] = dis_no / total_dis\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:179: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hispanic_prop\"] = hispanic / total_hisp\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:180: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_nonhispanic_prop\"] = nonhispanic / total_hisp\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:189: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_white_prop\"] = white / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:190: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_black_prop\"] = black / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_indian_prop\"] = indian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_asian_prop\"] = asian / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_race_PI_prop\"] = pi / total_race\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_veteran_prop\"] = veteran / pop_count\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:205: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_less_hs_prop\"] = less / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:206: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_hs_prop\"] = hs / edu_total\n",
      "/var/folders/t1/f9l59kf14m104mc7sxz3dzyc0000gn/T/ipykernel_24355/2043120649.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_final[f\"{year}_college_prop\"] = college / edu_total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final merged DataFrame (only proportions and median income) exported to /Users/ianpoe/Desktop/ga_county_proportions_2013_2022.csv\n",
      "                           2013_median_income code  2014_median_income  \\\n",
      "NAME                                                                     \n",
      "Appling County, Georgia                 36786  001               38461   \n",
      "Atkinson County, Georgia                30049  003               30403   \n",
      "Bacon County, Georgia                   33757  005               37698   \n",
      "Baker County, Georgia                   27353  007               45526   \n",
      "Baldwin County, Georgia                 32751  009               31758   \n",
      "...                                       ...  ...                 ...   \n",
      "Whitfield County, Georgia               40471  313               40081   \n",
      "Wilcox County, Georgia                  32928  315               32545   \n",
      "Wilkes County, Georgia                  28983  317               30729   \n",
      "Wilkinson County, Georgia               36173  319               37258   \n",
      "Worth County, Georgia                   35792  321               38339   \n",
      "\n",
      "                           2015_median_income  2016_median_income  \\\n",
      "NAME                                                                \n",
      "Appling County, Georgia                 37135               37388   \n",
      "Atkinson County, Georgia                30933               31296   \n",
      "Bacon County, Georgia                   37162               37303   \n",
      "Baker County, Georgia                   44297               45903   \n",
      "Baldwin County, Georgia                 32460               34595   \n",
      "...                                       ...                 ...   \n",
      "Whitfield County, Georgia               40596               41764   \n",
      "Wilcox County, Georgia                  32043               34071   \n",
      "Wilkes County, Georgia                  32727               33462   \n",
      "Wilkinson County, Georgia               38485               38827   \n",
      "Worth County, Georgia                   37974               38684   \n",
      "\n",
      "                           2017_median_income  2018_median_income  \\\n",
      "NAME                                                                \n",
      "Appling County, Georgia                 37089               39561   \n",
      "Atkinson County, Georgia                33063               34877   \n",
      "Bacon County, Georgia                   38824               36964   \n",
      "Baker County, Georgia                   43867               37188   \n",
      "Baldwin County, Georgia                 37008               39426   \n",
      "...                                       ...                 ...   \n",
      "Whitfield County, Georgia               43871               46970   \n",
      "Wilcox County, Georgia                  35457               36077   \n",
      "Wilkes County, Georgia                  34234               35106   \n",
      "Wilkinson County, Georgia               38711               37583   \n",
      "Worth County, Georgia                   40369               46076   \n",
      "\n",
      "                           2019_median_income  2020_median_income  \\\n",
      "NAME                                                                \n",
      "Appling County, Georgia                 40304               37924   \n",
      "Atkinson County, Georgia                37197               35703   \n",
      "Bacon County, Georgia                   37519               36692   \n",
      "Baker County, Georgia                   32917               34034   \n",
      "Baldwin County, Georgia                 43672               46250   \n",
      "...                                       ...                 ...   \n",
      "Whitfield County, Georgia               48623               50055   \n",
      "Wilcox County, Georgia                  36964               39216   \n",
      "Wilkes County, Georgia                  37838               36486   \n",
      "Wilkinson County, Georgia               38996               36896   \n",
      "Worth County, Georgia                   45398               50913   \n",
      "\n",
      "                           2021_median_income  ...  2022_nonhispanic_prop  \\\n",
      "NAME                                           ...                          \n",
      "Appling County, Georgia                 39588  ...               0.897077   \n",
      "Atkinson County, Georgia                35741  ...               0.726800   \n",
      "Bacon County, Georgia                   40391  ...               0.913090   \n",
      "Baker County, Georgia                   33417  ...               0.991661   \n",
      "Baldwin County, Georgia                 50413  ...               0.973480   \n",
      "...                                       ...  ...                    ...   \n",
      "Whitfield County, Georgia               52439  ...               0.632302   \n",
      "Wilcox County, Georgia                  41406  ...               0.952936   \n",
      "Wilkes County, Georgia                  43859  ...               0.943392   \n",
      "Wilkinson County, Georgia               34680  ...               0.968595   \n",
      "Worth County, Georgia                   54791  ...               0.974790   \n",
      "\n",
      "                           2022_race_white_prop  2022_race_black_prop  \\\n",
      "NAME                                                                    \n",
      "Appling County, Georgia                0.785486              0.201856   \n",
      "Atkinson County, Georgia               0.814197              0.185803   \n",
      "Bacon County, Georgia                  0.822407              0.167799   \n",
      "Baker County, Georgia                  0.538269              0.350858   \n",
      "Baldwin County, Georgia                0.547988              0.432973   \n",
      "...                                         ...                   ...   \n",
      "Whitfield County, Georgia              0.919411              0.039290   \n",
      "Wilcox County, Georgia                 0.650849              0.349033   \n",
      "Wilkes County, Georgia                 0.568860              0.429364   \n",
      "Wilkinson County, Georgia              0.600589              0.399175   \n",
      "Worth County, Georgia                  0.717089              0.269813   \n",
      "\n",
      "                           2022_race_indian_prop  2022_race_asian_prop  \\\n",
      "NAME                                                                     \n",
      "Appling County, Georgia                 0.006329              0.006329   \n",
      "Atkinson County, Georgia                0.000000              0.000000   \n",
      "Bacon County, Georgia                   0.002798              0.006996   \n",
      "Baker County, Georgia                   0.009299              0.101574   \n",
      "Baldwin County, Georgia                 0.001184              0.016458   \n",
      "...                                          ...                   ...   \n",
      "Whitfield County, Georgia               0.022484              0.018524   \n",
      "Wilcox County, Georgia                  0.000000              0.000000   \n",
      "Wilkes County, Georgia                  0.001776              0.000000   \n",
      "Wilkinson County, Georgia               0.000118              0.000118   \n",
      "Worth County, Georgia                   0.003619              0.009123   \n",
      "\n",
      "                           2022_race_PI_prop  2022_veteran_prop  \\\n",
      "NAME                                                              \n",
      "Appling County, Georgia             0.000000           0.034543   \n",
      "Atkinson County, Georgia            0.000000           0.037871   \n",
      "Bacon County, Georgia               0.000000           0.049201   \n",
      "Baker County, Georgia               0.000000           0.054204   \n",
      "Baldwin County, Georgia             0.001397           0.047581   \n",
      "...                                      ...                ...   \n",
      "Whitfield County, Georgia           0.000290           0.034474   \n",
      "Wilcox County, Georgia              0.000117           0.030773   \n",
      "Wilkes County, Georgia              0.000000           0.048595   \n",
      "Wilkinson County, Georgia           0.000000           0.045188   \n",
      "Worth County, Georgia               0.000357           0.062929   \n",
      "\n",
      "                           2022_less_hs_prop  2022_hs_prop  2022_college_prop  \n",
      "NAME                                                                           \n",
      "Appling County, Georgia             0.215664      0.594724           0.189612  \n",
      "Atkinson County, Georgia            0.295721      0.520300           0.183980  \n",
      "Bacon County, Georgia               0.153332      0.648416           0.198252  \n",
      "Baker County, Georgia               0.143066      0.526521           0.330414  \n",
      "Baldwin County, Georgia             0.145283      0.534597           0.320119  \n",
      "...                                      ...           ...                ...  \n",
      "Whitfield County, Georgia           0.257231      0.500958           0.241810  \n",
      "Wilcox County, Georgia              0.195622      0.598273           0.206105  \n",
      "Wilkes County, Georgia              0.173770      0.612687           0.213542  \n",
      "Wilkinson County, Georgia           0.106174      0.672819           0.221006  \n",
      "Worth County, Georgia               0.145467      0.655779           0.198754  \n",
      "\n",
      "[159 rows x 161 columns]\n"
     ]
    }
   ],
   "source": [
    "#uses census API to fetch the count of people with certain attributes in a given county for a given year\n",
    "#then, converts those counts to population proportions\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "API_KEY = os.getenv(\"CENSUS_API_KEY\")\n",
    "years = range(2013, 2023)  # 2013 to 2022 inclusive\n",
    "dfs = []\n",
    "url_template = \"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "\n",
    "# Updated base variable list (without geography fields)\n",
    "base_var_list = [\n",
    "    \"NAME\",\n",
    "    # Sex:\n",
    "    \"B01001_002E\",  # Male count\n",
    "    \"B01001_026E\",  # Female count\n",
    "    # Disability:\n",
    "    \"B18101_001E\",  # Total for disability status\n",
    "    \"B18101_004E\",  # Male, Under 5, with a disability\n",
    "    \"B18101_007E\",  # Male, 5 to 17, with a disability\n",
    "    \"B18101_010E\",  # Male, 18 to 34, with a disability\n",
    "    \"B18101_013E\",  # Male, 35 to 64, with a disability\n",
    "    \"B18101_016E\",  # Male, 65 to 74, with a disability\n",
    "    \"B18101_019E\",  # Male, 75 and over, with a disability\n",
    "    \"B18101_023E\",  # Female, Under 5, with a disability\n",
    "    \"B18101_026E\",  # Female, 5 to 17, with a disability\n",
    "    \"B18101_029E\",  # Female, 18 to 34, with a disability\n",
    "    \"B18101_032E\",  # Female, 35 to 64, with a disability\n",
    "    \"B18101_035E\",  # Female, 65 to 74, with a disability\n",
    "    \"B18101_038E\",  # Female, 75 and over, with a disability\n",
    "    # Hispanic ethnicity:\n",
    "    \"B03001_001E\",  # Total for Hispanic origin question\n",
    "    \"B03001_003E\",  # Hispanic or Latino\n",
    "    # Race (alone):\n",
    "    \"B02001_002E\",  # White alone\n",
    "    \"B02001_003E\",  # Black or African American alone\n",
    "    \"B02001_004E\",  # American Indian and Alaska Native alone\n",
    "    \"B02001_005E\",  # Asian alone\n",
    "    \"B02001_006E\",  # Native Hawaiian and Other Pacific Islander alone\n",
    "    # Veteran:\n",
    "    \"B21001_002E\",  # Veteran count\n",
    "    # Total population (for veteran proportion):\n",
    "    \"B01003_001E\",\n",
    "    # Education (for population 25+):\n",
    "    # Less than HS Diploma: B15003_002E to B15003_016E\n",
    "    \"B15003_002E\", \"B15003_003E\", \"B15003_004E\", \"B15003_005E\", \"B15003_006E\", \n",
    "    \"B15003_007E\", \"B15003_008E\", \"B15003_009E\", \"B15003_010E\", \"B15003_011E\", \n",
    "    \"B15003_012E\", \"B15003_013E\", \"B15003_014E\", \"B15003_015E\", \"B15003_016E\",\n",
    "    # High School Diploma Level: B15003_017E to B15003_020E\n",
    "    \"B15003_017E\", \"B15003_018E\", \"B15003_019E\", \"B15003_020E\",\n",
    "    # College+ Degree: B15003_021E to B15003_025E\n",
    "    \"B15003_021E\", \"B15003_022E\", \"B15003_023E\", \"B15003_024E\", \"B15003_025E\",\n",
    "    # Median Income:\n",
    "    \"B19013_001E\"\n",
    "]\n",
    "var_str = \",\".join(base_var_list)\n",
    "\n",
    "for year in years:\n",
    "    url = url_template.format(year=year)\n",
    "    params = {\n",
    "        \"get\": var_str,\n",
    "        \"for\": \"county:*\",  # All counties in Georgia\n",
    "        \"in\": \"state:13\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=40)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        df_year = pd.DataFrame(data[1:], columns=data[0])\n",
    "        \n",
    "        # Convert all numeric columns (all except \"NAME\") to numbers.\n",
    "        numeric_cols = [col for col in base_var_list if col != \"NAME\"]\n",
    "        for col in numeric_cols:\n",
    "            df_year[col] = pd.to_numeric(df_year[col], errors='coerce')\n",
    "        \n",
    "        # The API automatically appends \"state\" and \"county\". Drop \"state\" and rename \"county\" to \"code\".\n",
    "        if \"state\" in df_year.columns:\n",
    "            df_year.drop(columns=[\"state\"], inplace=True)\n",
    "        if \"county\" in df_year.columns:\n",
    "            df_year.rename(columns={\"county\": \"code\"}, inplace=True)\n",
    "        \n",
    "        # Create new raw count columns with the year prefix.\n",
    "        # Sex:\n",
    "        df_year[f\"{year}_male_count\"] = df_year[\"B01001_002E\"]\n",
    "        df_year[f\"{year}_female_count\"] = df_year[\"B01001_026E\"]\n",
    "        \n",
    "        # Disability: Sum the cells representing \"with a disability\" (both sexes & all age groups)\n",
    "        df_year[f\"{year}_disability_yes_count\"] = (\n",
    "            df_year[\"B18101_004E\"] + df_year[\"B18101_007E\"] + df_year[\"B18101_010E\"] +\n",
    "            df_year[\"B18101_013E\"] + df_year[\"B18101_016E\"] + df_year[\"B18101_019E\"] +\n",
    "            df_year[\"B18101_023E\"] + df_year[\"B18101_026E\"] + df_year[\"B18101_029E\"] +\n",
    "            df_year[\"B18101_032E\"] + df_year[\"B18101_035E\"] + df_year[\"B18101_038E\"]\n",
    "        )\n",
    "        df_year[f\"{year}_disability_no_count\"] = df_year[\"B18101_001E\"] - df_year[f\"{year}_disability_yes_count\"]\n",
    "        \n",
    "        # Hispanic:\n",
    "        df_year[f\"{year}_hispanic_count\"] = df_year[\"B03001_003E\"]\n",
    "        df_year[f\"{year}_nonhispanic_count\"] = df_year[\"B03001_001E\"] - df_year[\"B03001_003E\"]\n",
    "        \n",
    "        # Race:\n",
    "        df_year[f\"{year}_race_white_count\"] = df_year[\"B02001_002E\"]\n",
    "        df_year[f\"{year}_race_black_count\"] = df_year[\"B02001_003E\"]\n",
    "        df_year[f\"{year}_race_indian_count\"] = df_year[\"B02001_004E\"]\n",
    "        df_year[f\"{year}_race_asian_count\"] = df_year[\"B02001_005E\"]\n",
    "        df_year[f\"{year}_race_PI_count\"] = df_year[\"B02001_006E\"]\n",
    "        \n",
    "        # Veteran:\n",
    "        df_year[f\"{year}_veteran_count\"] = df_year[\"B21001_002E\"]\n",
    "        df_year[f\"{year}_pop_count\"] = df_year[\"B01003_001E\"]\n",
    "        \n",
    "        # Education:\n",
    "        edu_less_cols = [\n",
    "            \"B15003_002E\", \"B15003_003E\", \"B15003_004E\", \"B15003_005E\", \"B15003_006E\",\n",
    "            \"B15003_007E\", \"B15003_008E\", \"B15003_009E\", \"B15003_010E\", \"B15003_011E\",\n",
    "            \"B15003_012E\", \"B15003_013E\", \"B15003_014E\", \"B15003_015E\", \"B15003_016E\"\n",
    "        ]\n",
    "        edu_hs_cols = [\n",
    "            \"B15003_017E\", \"B15003_018E\", \"B15003_019E\", \"B15003_020E\"\n",
    "        ]\n",
    "        edu_college_cols = [\n",
    "            \"B15003_021E\", \"B15003_022E\", \"B15003_023E\", \"B15003_024E\", \"B15003_025E\"\n",
    "        ]\n",
    "        df_year[f\"{year}_less_hs_degree_count\"] = df_year[edu_less_cols].sum(axis=1)\n",
    "        df_year[f\"{year}_hs_degree_count\"] = df_year[edu_hs_cols].sum(axis=1)\n",
    "        df_year[f\"{year}_college_degree_count\"] = df_year[edu_college_cols].sum(axis=1)\n",
    "        \n",
    "        # Median Income:\n",
    "        df_year[f\"{year}_median_income\"] = df_year[\"B19013_001E\"]\n",
    "        \n",
    "        # Select only the new raw count columns plus \"code\"\n",
    "        cols_to_keep = [\n",
    "            f\"{year}_male_count\", f\"{year}_female_count\",\n",
    "            f\"{year}_disability_yes_count\", f\"{year}_disability_no_count\",\n",
    "            f\"{year}_hispanic_count\", f\"{year}_nonhispanic_count\",\n",
    "            f\"{year}_race_white_count\", f\"{year}_race_black_count\",\n",
    "            f\"{year}_race_indian_count\", f\"{year}_race_asian_count\",\n",
    "            f\"{year}_race_PI_count\", f\"{year}_veteran_count\",\n",
    "            f\"{year}_pop_count\",\n",
    "            f\"{year}_less_hs_degree_count\", f\"{year}_hs_degree_count\",\n",
    "            f\"{year}_college_degree_count\",\n",
    "            f\"{year}_median_income\",\n",
    "            \"code\"\n",
    "        ]\n",
    "        df_year = df_year[[\"NAME\"] + cols_to_keep]\n",
    "        df_year.set_index(\"NAME\", inplace=True)\n",
    "        \n",
    "        dfs.append(df_year)\n",
    "        print(f\"Data for {year} fetched and processed successfully.\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {year}: {e}\")\n",
    "\n",
    "# Merge all yearly DataFrames on the index (county name)\n",
    "if dfs:\n",
    "    df_final = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        df_final = df_final.join(df.drop(columns=[\"code\"]), how=\"outer\")\n",
    "    \n",
    "    # Calculate proportions for each year (separately for each county)\n",
    "    for year in years:\n",
    "        # Sex proportions\n",
    "        male = df_final[f\"{year}_male_count\"]\n",
    "        female = df_final[f\"{year}_female_count\"]\n",
    "        total_sex = male + female\n",
    "        df_final[f\"{year}_male_prop\"] = male / total_sex\n",
    "        df_final[f\"{year}_female_prop\"] = female / total_sex\n",
    "\n",
    "        # Disability proportions\n",
    "        dis_yes = df_final[f\"{year}_disability_yes_count\"]\n",
    "        dis_no = df_final[f\"{year}_disability_no_count\"]\n",
    "        total_dis = dis_yes + dis_no\n",
    "        df_final[f\"{year}_disability_yes_prop\"] = dis_yes / total_dis\n",
    "        df_final[f\"{year}_disability_no_prop\"] = dis_no / total_dis\n",
    "\n",
    "        # Hispanic proportions\n",
    "        hispanic = df_final[f\"{year}_hispanic_count\"]\n",
    "        nonhispanic = df_final[f\"{year}_nonhispanic_count\"]\n",
    "        total_hisp = hispanic + nonhispanic\n",
    "        df_final[f\"{year}_hispanic_prop\"] = hispanic / total_hisp\n",
    "        df_final[f\"{year}_nonhispanic_prop\"] = nonhispanic / total_hisp\n",
    "\n",
    "        # Race proportions\n",
    "        white = df_final[f\"{year}_race_white_count\"]\n",
    "        black = df_final[f\"{year}_race_black_count\"]\n",
    "        indian = df_final[f\"{year}_race_indian_count\"]\n",
    "        asian = df_final[f\"{year}_race_asian_count\"]\n",
    "        pi = df_final[f\"{year}_race_PI_count\"]\n",
    "        total_race = white + black + indian + asian + pi\n",
    "        df_final[f\"{year}_race_white_prop\"] = white / total_race\n",
    "        df_final[f\"{year}_race_black_prop\"] = black / total_race\n",
    "        df_final[f\"{year}_race_indian_prop\"] = indian / total_race\n",
    "        df_final[f\"{year}_race_asian_prop\"] = asian / total_race\n",
    "        df_final[f\"{year}_race_PI_prop\"] = pi / total_race\n",
    "\n",
    "        # Veteran proportion (using total population)\n",
    "        veteran = df_final[f\"{year}_veteran_count\"]\n",
    "        pop_count = df_final[f\"{year}_pop_count\"]\n",
    "        df_final[f\"{year}_veteran_prop\"] = veteran / pop_count\n",
    "\n",
    "        # Education proportions (for population 25+)\n",
    "        less = df_final[f\"{year}_less_hs_degree_count\"]\n",
    "        hs = df_final[f\"{year}_hs_degree_count\"]\n",
    "        college = df_final[f\"{year}_college_degree_count\"]\n",
    "        edu_total = less + hs + college\n",
    "        df_final[f\"{year}_less_hs_prop\"] = less / edu_total\n",
    "        df_final[f\"{year}_hs_prop\"] = hs / edu_total\n",
    "        df_final[f\"{year}_college_prop\"] = college / edu_total\n",
    "\n",
    "    # --- Remove the Raw Count Columns; Keep Only Proportion Columns, Median Income, and \"code\" ---\n",
    "    # Retain any column that ends with '_prop', '_median_income', or is \"code\"\n",
    "    keep_cols = [col for col in df_final.columns if col.endswith('_prop') or col.endswith('_median_income') or col == 'code']\n",
    "    df_final = df_final[keep_cols]\n",
    "    \n",
    "    output_filename = \"/Users/ianpoe/Desktop/ga_county_proportions_2013_2022.csv\"\n",
    "    df_final.to_csv(output_filename)\n",
    "    print(f\"\\nFinal merged DataFrame (only proportions and median income) exported to {output_filename}\")\n",
    "    print(df_final)\n",
    "else:\n",
    "    print(\"No data fetched for any year.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'race'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/machine-learning-env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m sample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Draw the sample.\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m sampled_df \u001b[38;5;241m=\u001b[39m sample_to_match_pop(df, pop_props, sample_size\u001b[38;5;241m=\u001b[39msample_size, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Verify balance by comparing distributions:\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled race distribution:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m, in \u001b[0;36msample_to_match_pop\u001b[0;34m(df, pop_props, sample_size, random_state)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Loop through each covariate in pop_props.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m covariate, target_props \u001b[38;5;129;01min\u001b[39;00m pop_props\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Compute observed proportions in the nonprofit data for the current covariate.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     observed \u001b[38;5;241m=\u001b[39m df[covariate]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# For each observation, compute the weight factor as:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m#   (target population proportion) / (observed nonprofit proportion)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# for the category that observation falls into.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweight_factor\u001b[39m(value):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/machine-learning-env/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/machine-learning-env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'race'"
     ]
    }
   ],
   "source": [
    "#performs stratified sampling on a dataset of interest. Uses population proportions for covariates to\n",
    "#capture a sample of dataset entries such that the sample proportions are a good match with the population proportions, overall\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sample_to_match_pop(df, pop_props, sample_size, random_state=None):\n",
    "    \"\"\"\n",
    "    Select a weighted random sample from `df` such that the weighted covariate\n",
    "    distributions match the target population proportions.\n",
    "    \n",
    "    Parameters:\n",
    "      df: pandas DataFrame with the nonprofit-level data.\n",
    "      pop_props: dict; keys are column names (e.g., 'race', 'gender') and values are\n",
    "                 dicts mapping each category to its population proportion.\n",
    "                 Example:\n",
    "                 {\n",
    "                   'race': {'asian': 0.35, 'black': 0.20, 'white': 0.45},\n",
    "                   'gender': {'male': 0.50, 'female': 0.50}\n",
    "                 }\n",
    "      sample_size: int; desired number of rows in the final sample.\n",
    "      random_state: int or None; for reproducibility.\n",
    "      \n",
    "    Returns:\n",
    "      A pandas DataFrame containing the sampled rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize weights as 1 for every observation.\n",
    "    weights = np.ones(len(df))\n",
    "    \n",
    "    # Loop through each covariate in pop_props.\n",
    "    for covariate, target_props in pop_props.items():\n",
    "        # Compute observed proportions in the nonprofit data for the current covariate.\n",
    "        observed = df[covariate].value_counts(normalize=True).to_dict()\n",
    "        \n",
    "        # For each observation, compute the weight factor as:\n",
    "        #   (target population proportion) / (observed nonprofit proportion)\n",
    "        # for the category that observation falls into.\n",
    "        def weight_factor(value):\n",
    "            if value in target_props and value in observed:\n",
    "                return target_props[value] / observed[value]\n",
    "            else:\n",
    "                # If a category is not provided in the target or is missing in the data,\n",
    "                # leave the weight unchanged.\n",
    "                return 1.0\n",
    "        \n",
    "        # Multiply the current weights by the weight factors for this covariate.\n",
    "        weights *= df[covariate].apply(weight_factor).values\n",
    "    \n",
    "    # Normalize the weights so they sum to 1.\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    # Sample from the DataFrame using the computed weights.\n",
    "    sampled_df = df.sample(n=sample_size, weights=weights, random_state=random_state)\n",
    "    return sampled_df\n",
    "\n",
    "# Example usage:\n",
    "# Assume df is your nonprofit-level pandas DataFrame containing columns 'race' and 'gender'\n",
    "# and you have the following target population proportions:\n",
    "pop_props = {\n",
    "    'race': {'asian': 0.35, 'black': 0.20, 'white': 0.45},\n",
    "    'gender': {'male': 0.50, 'female': 0.50}\n",
    "}\n",
    "\n",
    "# Specify desired sample size (e.g., 1000 rows).\n",
    "sample_size = 1000\n",
    "\n",
    "# Draw the sample.\n",
    "sampled_df = sample_to_match_pop(df, pop_props, sample_size=sample_size, random_state=42)\n",
    "\n",
    "# Verify balance by comparing distributions:\n",
    "print(\"Sampled race distribution:\")\n",
    "print(sampled_df['race'].value_counts(normalize=True))\n",
    "print(\"\\nTarget race distribution:\")\n",
    "print(pd.Series(pop_props['race']))\n",
    "\n",
    "print(\"\\nSampled gender distribution:\")\n",
    "print(sampled_df['gender'].value_counts(normalize=True))\n",
    "print(\"\\nTarget gender distribution:\")\n",
    "print(pd.Series(pop_props['gender']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 2013 fetched successfully.\n",
      "Data for 2014 fetched successfully.\n",
      "Data for 2015 fetched successfully.\n",
      "Data for 2016 fetched successfully.\n",
      "Data for 2017 fetched successfully.\n",
      "Data for 2018 fetched successfully.\n",
      "Data for 2019 fetched successfully.\n",
      "Data for 2020 fetched successfully.\n",
      "Data for 2021 fetched successfully.\n",
      "Data for 2022 fetched successfully.\n",
      "\n",
      "Final merged DataFrame:\n",
      "                           2013_pop code  2014_pop  2015_pop  2016_pop  \\\n",
      "NAME                                                                     \n",
      "Appling County, Georgia       18354  001     18421     18417     18410   \n",
      "Atkinson County, Georgia       8332  003      8297      8294      8268   \n",
      "Bacon County, Georgia         11159  005     11196     11222     11251   \n",
      "Baker County, Georgia          3410  007      3342      3292      3250   \n",
      "Baldwin County, Georgia       46018  009     45854     45795     45808   \n",
      "...                             ...  ...       ...       ...       ...   \n",
      "Whitfield County, Georgia    102556  313    103132    103456    103653   \n",
      "Wilcox County, Georgia         9110  315      9061      8972      8884   \n",
      "Wilkes County, Georgia        10265  317     10123      9991      9924   \n",
      "Wilkinson County, Georgia      9520  319      9455      9386      9312   \n",
      "Worth County, Georgia         21670  321     21365     21156     20988   \n",
      "\n",
      "                           2017_pop  2018_pop  2019_pop  2020_pop  2021_pop  \\\n",
      "NAME                                                                          \n",
      "Appling County, Georgia       18471     18454     18440     18428     18509   \n",
      "Atkinson County, Georgia       8313      8265      8239      8311      8269   \n",
      "Bacon County, Georgia         11279     11228     11201     11140     11163   \n",
      "Baker County, Georgia          3251      3189      3132      3090      2928   \n",
      "Baldwin County, Georgia       45527     45286     45111     45072     43876   \n",
      "...                             ...       ...       ...       ...       ...   \n",
      "Whitfield County, Georgia    103963    103849    104237    104122    103076   \n",
      "Wilcox County, Georgia         8896      8846      8824      8701      8841   \n",
      "Wilkes County, Georgia         9905      9884      9844      9797      9643   \n",
      "Wilkinson County, Georgia      9147      9078      9010      8945      8931   \n",
      "Worth County, Georgia         20809     20656     20494     20346     20824   \n",
      "\n",
      "                           2022_pop  \n",
      "NAME                                 \n",
      "Appling County, Georgia       18441  \n",
      "Atkinson County, Georgia       8265  \n",
      "Bacon County, Georgia         11138  \n",
      "Baker County, Georgia          2878  \n",
      "Baldwin County, Georgia       43778  \n",
      "...                             ...  \n",
      "Whitfield County, Georgia    103033  \n",
      "Wilcox County, Georgia         8839  \n",
      "Wilkes County, Georgia         9610  \n",
      "Wilkinson County, Georgia      8852  \n",
      "Worth County, Georgia         20706  \n",
      "\n",
      "[159 rows x 11 columns]\n",
      "\n",
      "Data exported to /Users/ianpoe/Desktop/population_by_county_2013_2022.csv\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/machine-learning-env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#using census API, fetches population for a given county in a given year\n",
    "\n",
    "API_KEY = os.getenv(\"CENSUS_API_KEY\")\n",
    "years = range(2013, 2023)  # 2013 to 2022 inclusive\n",
    "dfs = []\n",
    "url_template = \"https://api.census.gov/data/{year}/acs/acs5\"\n",
    "\n",
    "for year in years:\n",
    "    url = url_template.format(year=year)\n",
    "    params = {\n",
    "        \"get\": \"NAME,B01003_001E\",  # Total population\n",
    "        \"for\": \"county:*\",         # All counties in Georgia\n",
    "        \"in\": \"state:13\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=20)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        df_year = pd.DataFrame(data[1:], columns=data[0])\n",
    "        \n",
    "        # Rename columns:\n",
    "        # - B01003_001E -> <year>_pop (Total Population)\n",
    "        # - Rename \"county\" to \"code\" for consistency.\n",
    "        df_year.rename(columns={\n",
    "            \"B01003_001E\": f\"{year}_pop\",\n",
    "            \"county\": \"code\"\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Drop the \"state\" column (automatically appended by the API)\n",
    "        if \"state\" in df_year.columns:\n",
    "            df_year.drop(columns=[\"state\"], inplace=True)\n",
    "        \n",
    "        # Convert the population column to numeric\n",
    "        df_year[f\"{year}_pop\"] = pd.to_numeric(df_year[f\"{year}_pop\"], errors='coerce')\n",
    "        \n",
    "        # Set county name as the index.\n",
    "        df_year.set_index(\"NAME\", inplace=True)\n",
    "        \n",
    "        dfs.append(df_year)\n",
    "        print(f\"Data for {year} fetched successfully.\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for {year}: {e}\")\n",
    "\n",
    "# Merge all yearly DataFrames on the index (county name)\n",
    "if dfs:\n",
    "    df_final = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        # Drop duplicate \"code\" column from subsequent DataFrames\n",
    "        df_final = df_final.join(df.drop(columns=[\"code\"]), how=\"outer\")\n",
    "    \n",
    "    print(\"\\nFinal merged DataFrame:\")\n",
    "    print(df_final)\n",
    "    \n",
    "    # Export the final DataFrame to CSV\n",
    "    output_filename = \"/Users/ianpoe/Desktop/population_by_county_2013_2022.csv\"\n",
    "    df_final.to_csv(output_filename)\n",
    "    print(f\"\\nData exported to {output_filename}\")\n",
    "else:\n",
    "    print(\"No data fetched for any year.\")\n",
    "\n",
    "sys.exit(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
